{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6897c586-993e-4dd2-a20f-2260ee515a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "from transformers import pipeline\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618683e-3cf1-4062-9d8a-a694accfec1f",
   "metadata": {},
   "source": [
    "# Load Models and their Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d3286-0511-4b87-9c65-de9e8c712677",
   "metadata": {},
   "source": [
    "### GRU & Glove Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4509c310-d95e-48a7-b88c-d566a336dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = load_model('best_Glove_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d51b6827-002c-47a6-8615-1fbe949d9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer_GRU.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14e7f283-1a6e-4acf-b8b7-d337096b4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1434400f-88af-4d31-9796-2041debfecd5",
   "metadata": {},
   "source": [
    "### RandomForest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52a64361-4ac3-45c0-9850-f5af68e89724",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('random_forest_model.pkl', 'rb') as f:\n",
    "    rf_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8faad18-81df-4fa8-acaa-33b5da190f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc26e84b-ee97-40ca-99f5-6c2fa1ede357",
   "metadata": {},
   "source": [
    "### Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d37b7668-eac0-406c-92bc-7b617d650cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_tokenizer = AutoTokenizer.from_pretrained(r\"E:\\NLP\\content\\fake_news_model\")\n",
    "transformer_model = AutoModelForSequenceClassification.from_pretrained(r\"E:\\NLP\\content\\fake_news_model\")\n",
    "transformer_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "35e74a3c-6796-4115-8c0b-4dee19ac570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377ffcc2-2b71-4200-a263-908e4fcfca25",
   "metadata": {},
   "source": [
    "# Preprocessing & Prediction Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef6729ec-eca8-4760-8621-2d989495b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_rf(text):\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)\n",
    "    text = re.sub(r'<.*?>',' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z]',' ', text)\n",
    "    text = re.sub(r'\\s+',' ', text).strip()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1470b921-c999-4aa6-aea8-8ab80957d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rf(text):\n",
    "    processed = preprocessing_rf(text)\n",
    "    features = tfidf.transform([processed])\n",
    "    pred_prob = rf_model.predict_proba(features)[0][1]\n",
    "\n",
    "    if pred_prob >= 0.5:\n",
    "        label = \"Fake\"\n",
    "        percentage = pred_prob * 100\n",
    "    else:\n",
    "        label = \"Real\"\n",
    "        percentage = (1 - pred_prob) * 100\n",
    "    \n",
    "    return f\"{label} ({percentage:.2f}%)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c1a1eb-1f3b-4655-bc24-a35e99ed4ab6",
   "metadata": {},
   "source": [
    "# Preprocessing & Prediction GRU & Glove Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4e239e38-2f78-43ea-97d7-1aa3a43dadfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_gru(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)    \n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)    \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e21d5ec9-e2a9-4fd8-8386-ae7cb0969d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gru(text):\n",
    "    processed = preprocessing_gru(text)\n",
    "    sequence = tokenizer.texts_to_sequences([processed])\n",
    "    X_input = pad_sequences(sequence, maxlen=max_len)\n",
    "    pred_prob = float(gru_model.predict(X_input)[0][0])\n",
    "\n",
    "    if pred_prob >= 0.5:\n",
    "        label = \"Fake\"\n",
    "        percentage = pred_prob * 100\n",
    "    else:\n",
    "        label = \"Real\"\n",
    "        percentage = (1 - pred_prob) * 100\n",
    "\n",
    "    return f\"{label} ({percentage:.2f}%)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf9f770-f5f1-477e-a3f3-f6e6fbb92922",
   "metadata": {},
   "source": [
    "# Preprocessing & Prediction DistilBert (Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "faf1c0f0-adf2-47d0-a3bc-8b09068e2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_transformer(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "74e722b1-f6dd-4f0b-b6a4-68660dc787e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_transformer(text):\n",
    "    processed = preprocessing_transformer(text)\n",
    "    inputs = transformer_tokenizer(processed, padding=\"max_length\", truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = transformer_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)[0]\n",
    "    \n",
    "    pred_prob = float(probs[1]) \n",
    "\n",
    "    if pred_prob >= 0.5:\n",
    "        label = \"Fake\"\n",
    "        percentage = pred_prob * 100\n",
    "    else:\n",
    "        label = \"Real\"\n",
    "        percentage = (1 - pred_prob) * 100\n",
    "\n",
    "    return f\"{label} ({percentage:.2f}%)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519f095a-e7c7-4e93-b579-703b81c5e3ea",
   "metadata": {},
   "source": [
    "# Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e0923453-5e72-488d-ac45-4dc6956129e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ceef2b94799450a975a9d1a5312e6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\abdo\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\abdo\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8b9fd9c84d4f968d599e69e7131671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b182dc0ec24a12a26b4c73576a5cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6c4632e0534d9ba7bad2b54651eb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedd5a5bf778401080a29e652d284306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e62c3c9b27043fbb421da60cc010a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\",model=\"cardiffnlp/twitter-roberta-base-sentiment\",top_k=3)\n",
    "label_mapping = {\"LABEL_0\": -1.0, \"LABEL_1\": 0.0, \"LABEL_2\": 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c2a2db9f-f3a8-41cf-a311-70c2dbb8b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(text):\n",
    "    results = sentiment_pipeline(text)\n",
    "    positivity = 0.0\n",
    "    for label_score in results[0]:\n",
    "        label = label_score['label']\n",
    "        score = label_score['score']\n",
    "        if label in label_mapping:\n",
    "            positivity += label_mapping[label] * score\n",
    "    positivity = max(-1.0, min(1.0, positivity))\n",
    "    return positivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dfee92-a4f8-4415-8c67-bd1873f8d79e",
   "metadata": {},
   "source": [
    "# Procedural Smiley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "9e511d43-80de-40e8-bcfb-845f261e52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_label_from_score(score: float) -> str:\n",
    "    if score > 0.3:\n",
    "        return \"Positive 🙂\"\n",
    "    elif score < -0.3:\n",
    "        return \"Negative 😢\"\n",
    "    else:\n",
    "        return \"Neutral 😐\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "8fc25d55-36c5-41c4-a0a6-5f0d605c8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_image(positivity: float, image_size: tuple[int, int]=(200,200)) -> np.ndarray:\n",
    "    width, height = image_size\n",
    "    frame = np.zeros((height, width, 4), dtype=np.uint8)\n",
    "\n",
    "    color_outline = (0, 0, 0, 255)\n",
    "    thickness_outline = max(2, min(image_size) // 30)\n",
    "\n",
    "    center = (width // 2, height // 2)\n",
    "    radius = min(image_size) // 2 - thickness_outline\n",
    "\n",
    "    cv2.circle(frame, center, radius, color_outline, thickness_outline)\n",
    "\n",
    "    eye_radius = radius // 6\n",
    "    eye_offset_x = radius // 3\n",
    "    eye_offset_y = radius // 4\n",
    "    eye_left = (center[0] - eye_offset_x, center[1] - eye_offset_y)\n",
    "    eye_right = (center[0] + eye_offset_x, center[1] - eye_offset_y)\n",
    "\n",
    "    cv2.circle(frame, eye_left, eye_radius, color_outline, -1)\n",
    "    cv2.circle(frame, eye_right, eye_radius, color_outline, -1)\n",
    "\n",
    "    mouth_width = radius\n",
    "    mouth_height = radius // 3\n",
    "    mouth_offset_y = radius // 3\n",
    "    mouth_center_y = center[1] + mouth_offset_y\n",
    "\n",
    "    t = np.linspace(-1, 1, 100)\n",
    "    y = positivity * (t ** 2)\n",
    "    if positivity == 0:\n",
    "        y[:] = 0\n",
    "\n",
    "    pts = np.array([\n",
    "        (\n",
    "            int(center[0] + tx * mouth_width // 2),\n",
    "            int(mouth_center_y - ty * mouth_height)\n",
    "        )\n",
    "        for tx, ty in zip(t, y)\n",
    "    ], dtype=np.int32).reshape((-1, 1, 2))\n",
    "\n",
    "    cv2.polylines(frame, [pts], isClosed=False, color=color_outline, thickness=thickness_outline)\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89c2ee-ad78-4c21-bdb6-9b32ad678540",
   "metadata": {},
   "source": [
    "# Choose the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "41e557e5-7e2c-4e12-9a44-d2af1b44e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model_live(model_choice, text):\n",
    "    if text.strip() == \"\":\n",
    "        return \" \", np.zeros((200,200,3), dtype=np.uint8), \" \"\n",
    "\n",
    "    if model_choice == \"RandomForest\":\n",
    "        news_pred = predict_rf(text)\n",
    "    elif model_choice == \"GRU+GloVe\":\n",
    "        news_pred = predict_gru(text)\n",
    "    elif model_choice == \"Transformer\":\n",
    "        news_pred = predict_transformer(text)\n",
    "    else:\n",
    "        news_pred = \"Select a model\"\n",
    "\n",
    "    score = get_sentiment_score(text)\n",
    "    smiley_img = create_sentiment_image(score)\n",
    "    sentiment_label = sentiment_label_from_score(score)\n",
    "\n",
    "    return news_pred, smiley_img, sentiment_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "381fef66-a77d-4f98-bfb8-f6636a3efb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7900\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7900/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iface = gr.Interface(\n",
    "    fn=predict_model_live,\n",
    "    inputs=[\n",
    "        gr.Dropdown([\"RandomForest\", \"GRU+GloVe\", \"Transformer\"], label=\"Choose Model\"),\n",
    "        gr.Textbox(label=\"Enter your text here\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Prediction\"),\n",
    "        gr.Image(label=\"Sentiment Smiley\"),\n",
    "        gr.Textbox(label=\"Sentiment Label\")\n",
    "    ],\n",
    "    live=False\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e494c-ad24-4208-8702-8438bf3f52ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
